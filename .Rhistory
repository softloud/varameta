median(a_sample),
quantile(a_sample, 0.75),
)
?wan_mean_C3
wan_mean_C3(
quantile(a_sample, 0.25),
median(a_sample),
quantile(a_sample, 0.75)
)
wan_se_C3(
quantile(a_sample, 0.25),
median(a_sample),
quantile(a_sample, 0.75),
n = length(a_sample)
)
(a_sample <- rlnorm(sample_size,1, 0.1))
# summary statistics for this sample
a_sample %>% log() %>% summary()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# run this to update the pdf, as well
# rmarkdown::render("vignettes/varameta.Rmd", "all")
# for reproducibility
set.seed(39)
# packages
library(varameta)
library(tidyverse)
library(simeta)
library(panda)
# move to parameter when done with chunk-wise?
sample_size <- 10
panda("varameta:: is for meta-analysing medians")
panda("show me the code!")
# get a sample
a_sample <- rexp(sample_size)
# get standard error of the sample median
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# generate random meta-analysis dataset
# one row per study
(ma_sample <- sim_stats() %>%
# filter down to one group per study
dplyr::filter(group == "control"))
ma_sample %>%
# append a column with the standard error of the median for each study
mutate(effect_se = pmap_dbl(
list(centre = effect,
spread = effect_spread,
n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
))
(a_sample <- rlnorm(sample_size,1, 0.1))
# summary statistics for this sample
a_sample %>% log() %>% summary()
# taken from lognormal distribution
tibble(x = c(0, 1)) %>%
ggplot(aes(x = x)) +
geom_density(
data = tibble(x = a_sample),
aes(x = x),
alpha = 0.5,
fill = "darkgrey",
colour = "darkgrey"
) +
stat_function(
fun = dlnorm,
args = list(meanlog = -1,
sdlog = 0.1),
linetype = "dotted"
) +
labs(title = stringr::str_wrap("Sample from log-normal density", 30),
subtitle = stringr::str_wrap("Sample density in grey fill; true density, black dotted line"),
caption = "lognormal(-1, 0.01)")
# taken from lognormal distribution
tibble(x = c(0, 1)) %>%
ggplot(aes(x = x)) +
geom_density(
data = tibble(x = a_sample),
aes(x = x),
alpha = 0.5,
fill = "darkgrey",
colour = "darkgrey"
) +
stat_function(
fun = dlnorm,
args = list(meanlog = 1,
sdlog = 0.1),
linetype = "dotted"
) +
labs(title = stringr::str_wrap("Sample from log-normal density", 30),
subtitle = stringr::str_wrap("Sample density in grey fill; true density, black dotted line"),
caption = "lognormal(-1, 0.01)")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# run this to update the pdf, as well
# rmarkdown::render("vignettes/varameta.Rmd", "all")
# for reproducibility
set.seed(39)
# packages
library(varameta)
library(tidyverse)
library(simeta)
library(panda)
# move to parameter when done with chunk-wise?
sample_size <- 10
panda("varameta:: is for meta-analysing medians")
panda("show me the code!")
# get a sample
a_sample <- rexp(sample_size)
# get standard error of the sample median
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# generate random meta-analysis dataset
# one row per study
(ma_sample <- sim_stats() %>%
# filter down to one group per study
dplyr::filter(group == "control"))
ma_sample %>%
# append a column with the standard error of the median for each study
mutate(effect_se = pmap_dbl(
list(centre = effect,
spread = effect_spread,
n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
))
(a_sample <- rlnorm(sample_size,-1, 0.1))
# summary statistics for this sample
a_sample %>% log() %>% summary()
# taken from lognormal distribution
tibble(x = c(0, 1)) %>%
ggplot(aes(x = x)) +
geom_density(
data = tibble(x = a_sample),
aes(x = x),
alpha = 0.5,
fill = "darkgrey",
colour = "darkgrey"
) +
stat_function(
fun = dlnorm,
args = list(meanlog = -1,
sdlog = 0.1),
linetype = "dotted"
) +
labs(title = stringr::str_wrap("Sample from log-normal density", 30),
subtitle = stringr::str_wrap("Sample density in grey fill; true density, black dotted line"),
caption = "lognormal(-1, 0.01)")
exp(-1)
# for comparison we shall store the true distribution stats
true_stats <- list(
mean = exp(-1 + 0.01/2),
median = exp(-1),
variance = (exp(0.01) - 1) * exp(2*-1 + 0.01)
)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# run this to update the pdf, as well
# rmarkdown::render("vignettes/varameta.Rmd", "all")
# for reproducibility
set.seed(39)
# packages
library(varameta)
library(tidyverse)
library(simeta)
library(panda)
# move to parameter when done with chunk-wise?
sample_size <- 10
panda("varameta:: is for meta-analysing medians")
panda("show me the code!")
# get a sample
a_sample <- rexp(sample_size)
# get standard error of the sample median
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# generate random meta-analysis dataset
# one row per study
(ma_sample <- sim_stats() %>%
# filter down to one group per study
dplyr::filter(group == "control"))
ma_sample %>%
# append a column with the standard error of the median for each study
mutate(effect_se = pmap_dbl(
list(centre = effect,
spread = effect_spread,
n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
))
(a_sample <- rlnorm(sample_size,-1, 0.1))
# summary statistics for this sample
a_sample %>% log() %>% summary()
# taken from lognormal distribution
tibble(x = c(0, 1)) %>%
ggplot(aes(x = x)) +
geom_density(
data = tibble(x = a_sample),
aes(x = x),
alpha = 0.5,
fill = "darkgrey",
colour = "darkgrey"
) +
stat_function(
fun = dlnorm,
args = list(meanlog = -1,
sdlog = 0.1),
linetype = "dotted"
) +
labs(title = stringr::str_wrap("Sample from log-normal density", 30),
subtitle = stringr::str_wrap("Sample density in grey fill; true density, black dotted line"),
caption = "lognormal(-1, 0.01)")
# for comparison we shall store the true distribution stats
true_stats <- list(
mean = exp(-1 + 0.01/2),
median = exp(-1),
variance = (exp(0.01) - 1) * exp(2*-1 + 0.01)
)
# standard error based on the median, interquartile range, and sample size
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# standard error based on the median, range, and sample size
effect_se(
centre = median(a_sample),
spread = abs(diff(range(a_sample))),
n = length(a_sample),
centre_type = "median",
spread_type = "range"
)
panda("show me the math!")
# mean and sd
effect_se(
centre = mean(a_sample),
spread = sd(a_sample),
n = length(a_sample),
centre_type = "mean",
spread_type = "sd"
)
# compare
sd(a_sample) /
sqrt(length(a_sample))
# mean and var
effect_se(
centre = mean(a_sample),
spread = var(a_sample),
n = length(a_sample),
centre_type = "mean",
spread_type = "var"
)
# compare
sqrt(var(a_sample) /
length(a_sample))
panda("vectorisation is my favourite part of R", panda = 14)
# borrowing from sister package simeta:: to simulate a dataset
(meta_data <- sim_stats() %>%
dplyr::filter(group == "control"))
# each row of the dataset is a study
# add a column with the standar error for each study:
meta_data %>%
mutate(
effect_se = pmap_dbl(
list(centre = effect, spread = effect_spread, n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
)
)
# todo function this (after report)
pinheiro_data %>%
kableExtra::kable() %>%
kableExtra::kable_styling()
panda(panda = 49,
"varameta:: provides several estimators for the variances of the sample median")
# mean for the distribution sampled from
true_stats$mean
# variance for the distribution sampled from
true_stats$variance
# mean for the distribution sampled from
true_stats %>% pluck(mean)
# mean for the distribution sampled from
true_stats %>% pluck("mean")
# variance for the distribution sampled from
true_stats %>% pluck("variance")
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
?hozo
library(varameta)
?hozo_mean
# for reproducibility
set.seed(39)
# packages
library(varameta)
library(tidyverse)
library(simeta)
library(panda)
# move to parameter when done with chunk-wise?
sample_size <- 10
hozo_mean(
min(a_sample),
median(a_sample),
max(a_sample)
)
citr:::insert_citation()
?hozo_se
hozo_mean(
min(a_sample),
max(a_sample)
)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# run this to update the pdf, as well
# rmarkdown::render("vignettes/varameta.Rmd", "all")
# for reproducibility
set.seed(39)
# packages
library(varameta)
library(tidyverse)
library(simeta)
library(panda)
# move to parameter when done with chunk-wise?
sample_size <- 10
panda("varameta:: is for meta-analysing medians")
panda("show me the code!")
# get a sample
a_sample <- rlnorm(sample_size,-1, 0.1)
# get standard error of the sample median
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# generate random meta-analysis dataset
# one row per study
(ma_sample <- sim_stats() %>%
# filter down to one group per study
dplyr::filter(group == "control"))
ma_sample %>%
# append a column with the standard error of the median for each study
mutate(effect_se = pmap_dbl(
list(centre = effect,
spread = effect_spread,
n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
))
(a_sample <- rlnorm(sample_size,-1, 0.1))
# summary statistics for this sample
a_sample %>% log() %>% summary()
# taken from lognormal distribution
tibble(x = c(0, 1)) %>%
ggplot(aes(x = x)) +
geom_density(
data = tibble(x = a_sample),
aes(x = x),
alpha = 0.5,
fill = "darkgrey",
colour = "darkgrey"
) +
stat_function(
fun = dlnorm,
args = list(meanlog = -1,
sdlog = 0.1),
linetype = "dotted"
) +
labs(title = stringr::str_wrap("Sample from log-normal density", 30),
subtitle = stringr::str_wrap("Sample density in grey fill; true density, black dotted line"),
caption = "lognormal(-1, 0.01)")
# for comparison we shall store the true distribution stats
true_stats <- list(
mean = exp(-1 + 0.01/2),
median = exp(-1),
variance = (exp(0.01) - 1) * exp(2*-1 + 0.01)
)
# standard error based on the median, interquartile range, and sample size
effect_se(
centre = median(a_sample),
spread = IQR(a_sample),
n = length(a_sample),
centre_type = "median",
spread_type = "iqr"
)
# standard error based on the median, range, and sample size
effect_se(
centre = median(a_sample),
spread = abs(diff(range(a_sample))),
n = length(a_sample),
centre_type = "median",
spread_type = "range"
)
panda("show me the math!")
# mean and sd
effect_se(
centre = mean(a_sample),
spread = sd(a_sample),
n = length(a_sample),
centre_type = "mean",
spread_type = "sd"
)
# compare
sd(a_sample) /
sqrt(length(a_sample))
# mean and var
effect_se(
centre = mean(a_sample),
spread = var(a_sample),
n = length(a_sample),
centre_type = "mean",
spread_type = "var"
)
# compare
sqrt(var(a_sample) /
length(a_sample))
panda("vectorisation is my favourite part of R", panda = 14)
# borrowing from sister package simeta:: to simulate a dataset
(meta_data <- sim_stats() %>%
dplyr::filter(group == "control"))
# each row of the dataset is a study
# add a column with the standar error for each study:
meta_data %>%
mutate(
effect_se = pmap_dbl(
list(centre = effect, spread = effect_spread, n = n),
effect_se,
centre_type = "median",
spread_type = "iqr"
)
)
# todo function this (after report)
pinheiro_data %>%
kableExtra::kable() %>%
kableExtra::kable_styling()
panda(panda = 49,
"varameta:: provides several estimators for the variances of the sample median")
hozo_mean(
min(a_sample),
max(a_sample)
)
?hozo_mean
hozo_mean(
min(a_sample),
median(a_sample),
max(a_sample)
)
hozo_se(
min(a_sample),
median(a_sample),
max(a_sample),
n = length(a_sample)
)
?bland
library(varameta)
?bland_mean
library(varameta)
?g_exp
?g_cauchy
?g_lnorm
library(varameta)
covr::package_coverage()
covr::package_coverage()
reprex::reprex
reprex::reprex()
reprex::reprex()
reprex::reprex()
library(varameta)
reprex::reprex()
workflow(1)
c(7.3, 9, 5.2, 5.3,6,6.1,6.3,7.1) %>% sample(1)
c(6,6.1,6.21,0,1,1.1,1.2,1.3,2,4,5,7, 8)
c(6,6.1,6.21,0,1,1.1,1.2,1.3,2,4,5,7, 8) %>% sample(1)
neet::workflow(5)
neet::workflow(5)
c(6, 6.1,6.21, 0,1,1.1,1.2,1.3,2, 4,5,7,8) %>% sample(1)
